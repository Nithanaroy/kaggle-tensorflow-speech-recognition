{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Audio Recognition using Tensorflow\n",
    "\n",
    "This approach uses CNN to build a classifier for audio inputs"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Import necessary modules"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import tensorflow as tf\n",
    "from tensorflow.python.framework import ops\n",
    "from utils import *\n",
    "import datetime\n",
    "from time import time\n",
    "from tensorflow.python.client import timeline # for profiling\n",
    "\n",
    "%matplotlib inline\n",
    "np.random.seed(1)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Import the dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train_orig, Y_train_orig, X_test_orig, Y_test_orig, classes = load_data()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Explore the dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "number of training examples = 58248\n",
      "number of test examples = 6473\n",
      "X_train shape: (58248, 16000, 1, 1)\n",
      "Y_train shape: (58248, 30)\n",
      "X_test shape: (6473, 16000, 1, 1)\n",
      "Y_test shape: (6473, 30)\n"
     ]
    }
   ],
   "source": [
    "X_train = X_train_orig\n",
    "X_test = X_test_orig\n",
    "Y_train = convert_to_one_hot(Y_train_orig, classes)\n",
    "Y_test = convert_to_one_hot(Y_test_orig, classes)\n",
    "print (\"number of training examples = \" + str(X_train.shape[0]))\n",
    "print (\"number of test examples = \" + str(X_test.shape[0]))\n",
    "print (\"X_train shape: \" + str(X_train.shape))\n",
    "print (\"Y_train shape: \" + str(Y_train.shape))\n",
    "print (\"X_test shape: \" + str(X_test.shape))\n",
    "print (\"Y_test shape: \" + str(Y_test.shape))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Create input placeholders\n",
    "\n",
    "Tensorflow placeholders for X and Y. These will be dynamically set during batch G.D at runtime"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "def create_placeholders(n_l, n_y):\n",
    "    \"\"\"\n",
    "    Creates the placeholders for the tensorflow session.\n",
    "\n",
    "    Arguments:\n",
    "    n_l -- scalar, length of the audio vector\n",
    "    n_y -- scalar, number of classes\n",
    "\n",
    "    Returns:\n",
    "    X -- placeholder for the data input, of shape [None, n_l] and dtype \"float\"\n",
    "    Y -- placeholder for the input labels, of shape [None, n_y] and dtype \"float\"\n",
    "    \"\"\"\n",
    "    X = tf.placeholder(tf.float32, shape=(None, n_l, 1, 1))\n",
    "    Y = tf.placeholder(tf.float32, shape=(None, n_y))\n",
    "\n",
    "    return X, Y"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "# X, Y = create_placeholders(500, 20)\n",
    "# print (\"X = \" + str(X))\n",
    "# print (\"Y = \" + str(Y))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Initialize Parameters\n",
    "\n",
    "With tensorflow we only need to initialize parameters for Conv layers. Fully connected layers' paramaters are completed handled by the framework."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "def initialize_parameters():\n",
    "    \"\"\"\n",
    "    Initializes weight parameters to build a neural network with tensorflow. The shapes are:\n",
    "    W1 : [4, 1, 1, 8]\n",
    "    W2 : [2, 1, 8, 16]\n",
    "    Returns:\n",
    "    parameters -- a dictionary of tensors containing W1, W2\n",
    "    \"\"\"\n",
    "\n",
    "    tf.set_random_seed(1)\n",
    "\n",
    "    W1 = tf.get_variable(\"W1\", [4,1,1,8], initializer=tf.contrib.layers.xavier_initializer(seed = 0))\n",
    "    W2 = tf.get_variable(\"W2\", [2,1,8,16], initializer=tf.contrib.layers.xavier_initializer(seed = 0))\n",
    "\n",
    "    parameters = {\"W1\": W1, \"W2\": W2}\n",
    "\n",
    "    return parameters"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "# tf.reset_default_graph()\n",
    "# with tf.Session() as sess_test:\n",
    "#     parameters = initialize_parameters()\n",
    "#     init = tf.global_variables_initializer()\n",
    "#     sess_test.run(init)\n",
    "#     print(\"W1 = \" + str(parameters[\"W1\"].eval()[0,0,0]))\n",
    "#     print(\"W2 = \" + str(parameters[\"W2\"].eval()[0,0,0]))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Forward Propagation\n",
    "\n",
    "CONV2D -> RELU -> MAXPOOL -> CONV2D -> RELU -> MAXPOOL -> FLATTEN -> FULLYCONNECTED\n",
    "\n",
    "Following are the parameters for all the layers:\n",
    "    - Conv2D: stride 1, padding is \"SAME\"\n",
    "    - ReLU\n",
    "    - Max pool: 8 by 1 filter size and an 8 by 1 stride, padding is \"SAME\"\n",
    "    - Conv2D: stride 1, padding is \"SAME\"\n",
    "    - ReLU\n",
    "    - Max pool: 4 by 1 filter size and a 4 by 1 stride, padding is \"SAME\"\n",
    "    - Flatten the previous output.\n",
    "    - FULLYCONNECTED (FC) layer: outputs 30 classes one for each audio utterance"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "def forward_propagation(X, parameters):\n",
    "    \"\"\"\n",
    "    Implements the forward propagation for the model:\n",
    "    CONV2D -> RELU -> MAXPOOL -> CONV2D -> RELU -> MAXPOOL -> FLATTEN -> FULLYCONNECTED\n",
    "\n",
    "    Arguments:\n",
    "    X -- input dataset placeholder, of shape (input size, number of examples)\n",
    "    parameters -- python dictionary containing parameters \"W1\", \"W2\"\n",
    "    the shapes are given in initialize_parameters\n",
    "    Returns:\n",
    "    Z3 -- the output of the last LINEAR unit\n",
    "    \"\"\"\n",
    "\n",
    "    # Retrieve the parameters from the dictionary \"parameters\"\n",
    "    W1 = parameters['W1']\n",
    "    W2 = parameters['W2']\n",
    "\n",
    "    Z1 = tf.nn.conv2d(X, W1, strides = [1,1,1,1], padding = 'SAME')\n",
    "    A1 = tf.nn.relu(Z1)\n",
    "    P1 = tf.nn.max_pool(A1, ksize = [1,8,1,1], strides = [1,8,1,1], padding = 'SAME')\n",
    "    Z2 = tf.nn.conv2d(P1, W2, strides = [1,1,1,1], padding = 'SAME')\n",
    "    A2 = tf.nn.relu(Z2)\n",
    "    P2 = tf.nn.max_pool(A2, ksize = [1,4,1,1], strides = [1,4,1,1], padding = 'SAME')\n",
    "    P2 = tf.contrib.layers.flatten(P2)\n",
    "    Z3 = tf.contrib.layers.fully_connected(P2, 30, activation_fn=None)\n",
    "\n",
    "    return Z3"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "# tf.reset_default_graph()\n",
    "# with tf.Session() as sess:\n",
    "#     np.random.seed(1)\n",
    "#     X, Y = create_placeholders(64, 5)\n",
    "#     parameters = initialize_parameters()\n",
    "#     Z3 = forward_propagation(X, parameters)\n",
    "#     init = tf.global_variables_initializer()\n",
    "#     sess.run(init)\n",
    "#     a = sess.run(Z3, {X: np.random.randn(2,64,1,1), Y: np.random.randn(2,5)})\n",
    "#     print(\"Z3 = \" + str(a))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Compute Cost\n",
    "\n",
    "Using the last layer Z3, compute softmax and J"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "def compute_cost(Z3, Y):\n",
    "    \"\"\"\n",
    "    Computes the cost\n",
    "\n",
    "    Arguments:\n",
    "    Z3 -- output of forward propagation (output of the last LINEAR unit), of shape (30, number of examples)\n",
    "    Y -- \"true\" labels vector placeholder, same shape as Z3\n",
    "\n",
    "    Returns:\n",
    "    cost - Tensor of the cost function\n",
    "    \"\"\"\n",
    "\n",
    "    cost = tf.reduce_mean(tf.nn.softmax_cross_entropy_with_logits(logits = Z3, labels = Y))\n",
    "\n",
    "    return cost"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "# tf.reset_default_graph()\n",
    "# with tf.Session() as sess:\n",
    "#     np.random.seed(1)\n",
    "#     X, Y = create_placeholders(64, 30)\n",
    "#     parameters = initialize_parameters()\n",
    "#     Z3 = forward_propagation(X, parameters)\n",
    "#     cost = compute_cost(Z3, Y)\n",
    "#     init = tf.global_variables_initializer()\n",
    "#     sess.run(init)\n",
    "#     a = sess.run(cost, {X: np.random.randn(4,64,1,1), Y: np.random.randn(4,30)})\n",
    "#     print(\"cost = \" + str(a))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Model\n",
    "\n",
    "Connects all the functions and sets up training with mini batches"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "tf.reset_default_graph() # to be able to rerun the model without overwriting tf variables\n",
    "\n",
    "config = tf.ConfigProto(device_count = {'GPU': 0})\n",
    "\n",
    "# Start an interactive session\n",
    "sess = tf.InteractiveSession(config=config)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Profiling"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "options = tf.RunOptions(trace_level=tf.RunOptions.FULL_TRACE)\n",
    "run_metadata = tf.RunMetadata()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "def model(sess, X_train, Y_train, X_test, Y_test, learning_rate = 0.009, num_epochs = 100, \n",
    "          minibatch_size = 64, print_cost = True):\n",
    "    \"\"\"\n",
    "    Implements a three-layer ConvNet in Tensorflow:\n",
    "    CONV2D -> RELU -> MAXPOOL -> CONV2D -> RELU -> MAXPOOL -> FLATTEN -> FULLYCONNECTED\n",
    "\n",
    "    Arguments:\n",
    "    X_train -- training set, of shape (None, 16000, 1, 1)\n",
    "    Y_train -- test set, of shape (None, n_y = 30)\n",
    "    X_test -- training set, of shape (None, 16000, 1, 1)\n",
    "    Y_test -- test set, of shape (None, n_y = 30)\n",
    "    learning_rate -- learning rate of the optimization\n",
    "    num_epochs -- number of epochs of the optimization loop\n",
    "    minibatch_size -- size of a minibatch\n",
    "    print_cost -- True to print the cost every 100 epochs\n",
    "\n",
    "    Returns:\n",
    "    train_accuracy -- real number, accuracy on the train set (X_train)\n",
    "    test_accuracy -- real number, testing accuracy on the test set (X_test)\n",
    "    parameters -- parameters learnt by the model. They can then be used to predict.\n",
    "    \"\"\"\n",
    "\n",
    "    tf.set_random_seed(1) # to keep results consistent (tensorflow seed)\n",
    "    seed = 3 # to keep results consistent (numpy seed)\n",
    "    (m, n_l, _, __) = X_train.shape\n",
    "    n_y = Y_train.shape[1]\n",
    "    costs = [] # To keep track of the cost\n",
    "\n",
    "    X, Y = create_placeholders(n_l, n_y)\n",
    "    parameters = initialize_parameters()\n",
    "    Z3 = forward_propagation(X, parameters)\n",
    "    cost = compute_cost(Z3, Y)\n",
    "    # print(\"Cost before iteration %s\" % (cost,))\n",
    "\n",
    "    # Backpropagation: Using AdamOptimizer to minimize the cost.\n",
    "    optimizer = tf.train.AdamOptimizer(learning_rate = learning_rate).minimize(cost)\n",
    "\n",
    "    # Run the initialization\n",
    "    sess.run(tf.global_variables_initializer())\n",
    "    num_minibatches = int(m / minibatch_size) # number of minibatches of size minibatch_size in the train set\n",
    "    \n",
    "    \n",
    "    \n",
    "    # Do the training loop\n",
    "    for epoch in range(num_epochs):\n",
    "        minibatch_cost = 0.\n",
    "        # print(\"> epoch = %s, m = %s, mini size = %s, mini cost = %s\" % (epoch, m, minibatch_size, minibatch_cost))\n",
    "        seed = seed + 1\n",
    "        minibatches = random_mini_batches(X_train, Y_train, minibatch_size, seed)\n",
    "        for minibatch in minibatches:\n",
    "            (minibatch_X, minibatch_Y) = minibatch\n",
    "            # print(\">> mini X.shape = %s, mini Y.shape = %s\" % (minibatch_X.shape, minibatch_Y.shape))\n",
    "            # IMPORTANT: The line that runs the graph on a minibatch.\n",
    "            # Run the session to execute the optimizer and the cost, the feedict should contain a minibatch for (X,Y).\n",
    "            _ , temp_cost = sess.run([optimizer, cost], feed_dict = {X: minibatch_X, Y: minibatch_Y})\n",
    "            # print(\">> Temp cost = %s\" % temp_cost)\n",
    "            minibatch_cost += temp_cost / num_minibatches\n",
    "\n",
    "        # Print the cost every epoch\n",
    "        if print_cost == True and epoch % 1 == 0:\n",
    "            print(\"%s: Cost after epoch %i: %f\" % (datetime.datetime.now().strftime('%Y-%m-%d %H:%M:%S'), epoch, minibatch_cost))\n",
    "        if print_cost == True and epoch % 1 == 0:\n",
    "            costs.append(minibatch_cost)\n",
    "\n",
    "\n",
    "    # plot the cost\n",
    "    plt.plot(np.squeeze(costs))\n",
    "    plt.ylabel('cost')\n",
    "    plt.xlabel('iterations (per tens)')\n",
    "    plt.title(\"Learning rate =\" + str(learning_rate))\n",
    "    plt.show()\n",
    "\n",
    "    return Z3, X, Y, parameters"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2018-01-04 08:58:46: Cost after epoch 0: 2.904873\n",
      "2018-01-04 08:59:53: Cost after epoch 1: 2.469891\n",
      "2018-01-04 09:00:59: Cost after epoch 2: 2.207325\n",
      "2018-01-04 09:02:05: Cost after epoch 3: 1.963910\n",
      "2018-01-04 09:03:11: Cost after epoch 4: 1.766639\n",
      "2018-01-04 09:04:17: Cost after epoch 5: 1.589114\n",
      "2018-01-04 09:05:23: Cost after epoch 6: 1.459018\n",
      "2018-01-04 09:06:29: Cost after epoch 7: 1.343035\n",
      "2018-01-04 09:07:35: Cost after epoch 8: 1.260475\n",
      "2018-01-04 09:08:40: Cost after epoch 9: 1.180428\n",
      "2018-01-04 09:09:46: Cost after epoch 10: 1.109371\n",
      "2018-01-04 09:10:52: Cost after epoch 11: 1.058131\n",
      "2018-01-04 09:11:58: Cost after epoch 12: 0.995226\n",
      "2018-01-04 09:13:04: Cost after epoch 13: 0.956141\n",
      "2018-01-04 09:14:10: Cost after epoch 14: 0.915367\n",
      "2018-01-04 09:15:15: Cost after epoch 15: 0.868854\n",
      "2018-01-04 09:16:21: Cost after epoch 16: 0.857897\n",
      "2018-01-04 09:17:28: Cost after epoch 17: 0.815753\n",
      "2018-01-04 09:18:34: Cost after epoch 18: 0.787724\n",
      "2018-01-04 09:19:40: Cost after epoch 19: 0.762876\n",
      "2018-01-04 09:20:47: Cost after epoch 20: 0.756782\n",
      "2018-01-04 09:21:52: Cost after epoch 21: 0.713669\n",
      "2018-01-04 09:22:58: Cost after epoch 22: 0.679858\n",
      "2018-01-04 09:24:04: Cost after epoch 23: 0.676655\n",
      "2018-01-04 09:25:10: Cost after epoch 24: 0.635792\n",
      "2018-01-04 09:26:15: Cost after epoch 25: 0.650293\n",
      "2018-01-04 09:27:21: Cost after epoch 26: 0.681165\n",
      "2018-01-04 09:28:27: Cost after epoch 27: 0.649024\n",
      "2018-01-04 09:29:33: Cost after epoch 28: 0.606861\n",
      "2018-01-04 09:30:38: Cost after epoch 29: 0.566579\n",
      "2018-01-04 09:31:44: Cost after epoch 30: 0.561014\n",
      "2018-01-04 09:32:50: Cost after epoch 31: 0.562964\n",
      "2018-01-04 09:33:56: Cost after epoch 32: 0.545746\n",
      "2018-01-04 09:35:01: Cost after epoch 33: 0.524013\n",
      "2018-01-04 09:36:07: Cost after epoch 34: 0.541064\n",
      "2018-01-04 09:37:13: Cost after epoch 35: 0.546322\n",
      "2018-01-04 09:38:19: Cost after epoch 36: 0.515132\n",
      "2018-01-04 09:39:25: Cost after epoch 37: 0.492907\n",
      "2018-01-04 09:40:30: Cost after epoch 38: 0.480975\n",
      "2018-01-04 09:41:36: Cost after epoch 39: 0.480107\n",
      "2018-01-04 09:42:42: Cost after epoch 40: 0.461168\n",
      "2018-01-04 09:43:47: Cost after epoch 41: 0.498665\n",
      "2018-01-04 09:44:53: Cost after epoch 42: 0.483158\n",
      "2018-01-04 09:45:59: Cost after epoch 43: 0.479439\n",
      "2018-01-04 09:47:04: Cost after epoch 44: 0.497089\n",
      "2018-01-04 09:48:11: Cost after epoch 45: 0.456449\n",
      "2018-01-04 09:49:16: Cost after epoch 46: 0.411808\n",
      "2018-01-04 09:50:22: Cost after epoch 47: 0.407111\n",
      "2018-01-04 09:51:28: Cost after epoch 48: 0.401214\n",
      "2018-01-04 09:52:34: Cost after epoch 49: 0.440881\n",
      "2018-01-04 09:53:39: Cost after epoch 50: 0.475378\n",
      "2018-01-04 09:54:45: Cost after epoch 51: 0.435961\n",
      "2018-01-04 09:55:51: Cost after epoch 52: 0.388614\n",
      "2018-01-04 09:56:57: Cost after epoch 53: 0.358064\n",
      "2018-01-04 09:58:02: Cost after epoch 54: 0.396765\n",
      "2018-01-04 09:59:08: Cost after epoch 55: 0.425200\n",
      "2018-01-04 10:00:14: Cost after epoch 56: 0.377592\n",
      "2018-01-04 10:01:20: Cost after epoch 57: 0.368942\n",
      "2018-01-04 10:02:26: Cost after epoch 58: 0.376179\n",
      "2018-01-04 10:03:32: Cost after epoch 59: 0.341830\n",
      "2018-01-04 10:04:37: Cost after epoch 60: 0.418040\n",
      "2018-01-04 10:05:43: Cost after epoch 61: 0.378031\n",
      "2018-01-04 10:06:48: Cost after epoch 62: 0.360696\n",
      "2018-01-04 10:07:54: Cost after epoch 63: 0.346959\n",
      "2018-01-04 10:08:59: Cost after epoch 64: 0.330611\n",
      "2018-01-04 10:10:05: Cost after epoch 65: 0.350502\n",
      "2018-01-04 10:11:11: Cost after epoch 66: 0.320776\n",
      "2018-01-04 10:12:17: Cost after epoch 67: 0.324028\n",
      "2018-01-04 10:13:22: Cost after epoch 68: 0.372380\n",
      "2018-01-04 10:14:28: Cost after epoch 69: 0.334770\n",
      "2018-01-04 10:15:33: Cost after epoch 70: 0.323316\n",
      "2018-01-04 10:16:39: Cost after epoch 71: 0.314573\n",
      "2018-01-04 10:17:45: Cost after epoch 72: 0.328583\n",
      "2018-01-04 10:18:51: Cost after epoch 73: 0.342560\n",
      "2018-01-04 10:19:57: Cost after epoch 74: 0.295163\n",
      "2018-01-04 10:21:02: Cost after epoch 75: 0.303714\n",
      "2018-01-04 10:22:07: Cost after epoch 76: 0.279682\n",
      "2018-01-04 10:23:13: Cost after epoch 77: 0.292762\n",
      "2018-01-04 10:24:19: Cost after epoch 78: 0.273703\n",
      "2018-01-04 10:25:25: Cost after epoch 79: 0.337216\n",
      "2018-01-04 10:26:31: Cost after epoch 80: 0.291159\n",
      "2018-01-04 10:27:36: Cost after epoch 81: 0.274340\n",
      "2018-01-04 10:28:42: Cost after epoch 82: 0.275537\n",
      "2018-01-04 10:29:48: Cost after epoch 83: 0.287421\n",
      "2018-01-04 10:30:54: Cost after epoch 84: 0.287695\n",
      "2018-01-04 10:32:00: Cost after epoch 85: 0.263942\n",
      "2018-01-04 10:33:06: Cost after epoch 86: 0.282452\n",
      "2018-01-04 10:34:11: Cost after epoch 87: 0.297683\n",
      "2018-01-04 10:35:17: Cost after epoch 88: 0.302917\n",
      "2018-01-04 10:36:23: Cost after epoch 89: 0.244739\n",
      "2018-01-04 10:37:29: Cost after epoch 90: 0.311202\n",
      "2018-01-04 10:38:34: Cost after epoch 91: 0.245966\n",
      "2018-01-04 10:39:40: Cost after epoch 92: 0.251805\n",
      "2018-01-04 10:40:46: Cost after epoch 93: 0.226847\n",
      "2018-01-04 10:41:52: Cost after epoch 94: 0.278148\n",
      "2018-01-04 10:42:58: Cost after epoch 95: 0.275546\n",
      "2018-01-04 10:44:04: Cost after epoch 96: 0.277893\n",
      "2018-01-04 10:45:10: Cost after epoch 97: 0.260896\n",
      "2018-01-04 10:46:16: Cost after epoch 98: 0.255108\n",
      "2018-01-04 10:47:22: Cost after epoch 99: 0.250997\n"
     ]
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<matplotlib.figure.Figure at 0x201c850>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "Z3, X, Y, parameters = model(sess, X_train, Y_train, X_test, Y_test, minibatch_size = 256, num_epochs = 100)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Save profilind data to disk"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create the Timeline object, and write it to a json file\n",
    "fetched_timeline = timeline.Timeline(run_metadata.step_stats)\n",
    "chrome_trace = fetched_timeline.generate_chrome_trace_format()\n",
    "time_id = int(time())\n",
    "with open('../experiments/timeline_256b_15e_gpu0_%s.json' % (time_id,), 'w') as f:\n",
    "    f.write(chrome_trace)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Save model to disk"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# saver = tf.train.Saver()\n",
    "# saver.save(sess, '../saved_models/cnn-tf-model')\n",
    "\n",
    "meta_graph_def = tf.train.export_meta_graph(filename='../saved_models/my-cnn-tf-model.meta')\n",
    "meta_graph_def"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "W1 = [ 3.61501765 -2.38024473  1.26850009 -2.43922925 -2.17123342  1.85708487\n",
      " -2.77779675  2.41049075]\n"
     ]
    }
   ],
   "source": [
    "print(\"W1 = \" + str(parameters[\"W1\"].eval()[0,0,0]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(tf.train.latest_checkpoint('../saved_models/'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [],
   "source": [
    "def model_accuracy(X_train, Y_train, Z3, X, Y, minibatch_size = 64, print_progress = True):\n",
    "    predict_op = tf.argmax(Z3, 1)\n",
    "    correct_prediction = tf.equal(predict_op, tf.argmax(Y, 1))\n",
    "    accuracy = tf.reduce_mean(tf.cast(correct_prediction, \"float\"))\n",
    "    \n",
    "    num_minibatches = 0\n",
    "    acc_accuracy = 0\n",
    "    minibatches = random_mini_batches(X_train, Y_train, minibatch_size)\n",
    "    for minibatch in minibatches:\n",
    "        (minibatch_X, minibatch_Y) = minibatch\n",
    "        acc_accuracy += accuracy.eval({X: minibatch_X, Y: minibatch_Y})\n",
    "        num_minibatches += 1\n",
    "        \n",
    "        if num_minibatches % 5 == 0:\n",
    "            print(\"%s: Accuracy after %ith batch: %f\" % (datetime.datetime.now().strftime('%Y-%m-%d %H:%M:%S'), num_minibatches, acc_accuracy / num_minibatches))\n",
    "\n",
    "    train_accuracy = acc_accuracy / num_minibatches\n",
    "    print(\"Accuracy:\", train_accuracy)\n",
    "\n",
    "    return train_accuracy"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[_DeviceAttributes(/job:localhost/replica:0/task:0/device:CPU:0, CPU, 268435456)]"
      ]
     },
     "execution_count": 21,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "sess.list_devices()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2018-01-04 12:39:02: Accuracy after 5th batch: 0.933594\n",
      "2018-01-04 12:39:03: Accuracy after 10th batch: 0.931641\n",
      "2018-01-04 12:39:03: Accuracy after 15th batch: 0.926562\n",
      "2018-01-04 12:39:03: Accuracy after 20th batch: 0.926758\n",
      "2018-01-04 12:39:04: Accuracy after 25th batch: 0.928594\n",
      "2018-01-04 12:39:04: Accuracy after 30th batch: 0.929948\n",
      "2018-01-04 12:39:05: Accuracy after 35th batch: 0.928237\n",
      "2018-01-04 12:39:05: Accuracy after 40th batch: 0.928613\n",
      "2018-01-04 12:39:06: Accuracy after 45th batch: 0.928212\n",
      "2018-01-04 12:39:06: Accuracy after 50th batch: 0.928828\n",
      "2018-01-04 12:39:06: Accuracy after 55th batch: 0.928551\n",
      "2018-01-04 12:39:07: Accuracy after 60th batch: 0.929167\n",
      "2018-01-04 12:39:07: Accuracy after 65th batch: 0.929087\n",
      "2018-01-04 12:39:08: Accuracy after 70th batch: 0.928962\n",
      "2018-01-04 12:39:08: Accuracy after 75th batch: 0.928125\n",
      "2018-01-04 12:39:09: Accuracy after 80th batch: 0.927393\n",
      "2018-01-04 12:39:09: Accuracy after 85th batch: 0.927574\n",
      "2018-01-04 12:39:09: Accuracy after 90th batch: 0.927517\n",
      "2018-01-04 12:39:10: Accuracy after 95th batch: 0.928207\n",
      "2018-01-04 12:39:10: Accuracy after 100th batch: 0.928555\n",
      "2018-01-04 12:39:11: Accuracy after 105th batch: 0.928609\n",
      "2018-01-04 12:39:11: Accuracy after 110th batch: 0.928729\n",
      "2018-01-04 12:39:12: Accuracy after 115th batch: 0.929314\n",
      "2018-01-04 12:39:12: Accuracy after 120th batch: 0.929427\n",
      "2018-01-04 12:39:12: Accuracy after 125th batch: 0.928625\n",
      "2018-01-04 12:39:13: Accuracy after 130th batch: 0.929207\n",
      "2018-01-04 12:39:13: Accuracy after 135th batch: 0.929659\n",
      "2018-01-04 12:39:14: Accuracy after 140th batch: 0.929967\n",
      "2018-01-04 12:39:14: Accuracy after 145th batch: 0.930038\n",
      "2018-01-04 12:39:15: Accuracy after 150th batch: 0.930130\n",
      "2018-01-04 12:39:15: Accuracy after 155th batch: 0.930040\n",
      "2018-01-04 12:39:15: Accuracy after 160th batch: 0.929956\n",
      "2018-01-04 12:39:16: Accuracy after 165th batch: 0.929995\n",
      "2018-01-04 12:39:16: Accuracy after 170th batch: 0.930055\n",
      "2018-01-04 12:39:17: Accuracy after 175th batch: 0.929576\n",
      "2018-01-04 12:39:17: Accuracy after 180th batch: 0.929601\n",
      "2018-01-04 12:39:17: Accuracy after 185th batch: 0.929413\n",
      "2018-01-04 12:39:18: Accuracy after 190th batch: 0.929626\n",
      "2018-01-04 12:39:18: Accuracy after 195th batch: 0.929447\n",
      "2018-01-04 12:39:19: Accuracy after 200th batch: 0.929688\n",
      "2018-01-04 12:39:19: Accuracy after 205th batch: 0.929364\n",
      "2018-01-04 12:39:20: Accuracy after 210th batch: 0.929260\n",
      "2018-01-04 12:39:20: Accuracy after 215th batch: 0.929142\n",
      "2018-01-04 12:39:20: Accuracy after 220th batch: 0.929208\n",
      "2018-01-04 12:39:21: Accuracy after 225th batch: 0.929306\n",
      "('Accuracy:', 0.92930957335129116)\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "0.92930957335129116"
      ]
     },
     "execution_count": 35,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# train_accuracy, test_accuracy = model_accuracy(X_train, Y_train, X_test, Y_test, Z3, X, Y)\n",
    "# test_accuracy = model_accuracy(X_train, Y_train, X_test, Y_test, Z3, X, Y)\n",
    "model_accuracy(X_train, Y_train, Z3, X, Y, minibatch_size = 256)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2018-01-04 12:38:43: Accuracy after 5th batch: 0.265625\n",
      "2018-01-04 12:38:43: Accuracy after 10th batch: 0.270703\n",
      "2018-01-04 12:38:43: Accuracy after 15th batch: 0.271615\n",
      "2018-01-04 12:38:44: Accuracy after 20th batch: 0.265039\n",
      "2018-01-04 12:38:44: Accuracy after 25th batch: 0.265781\n",
      "('Accuracy:', 0.26398882040610683)\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "0.26398882040610683"
      ]
     },
     "execution_count": 33,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model_accuracy(X_test, Y_test, Z3, X, Y, minibatch_size = 256)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Inference\n",
    "\n",
    "- Convert audio file to vector and reshape\n",
    "- Do forward prop\n",
    "- Find the maximal class\n",
    "- Remap index to class name"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "metadata": {},
   "outputs": [],
   "source": [
    "def inference(audio_file, Z3):\n",
    "    ra = load_wav_file(os.path.abspath(audio_file))\n",
    "    x = ra.reshape(1, ra.shape[0], 1, 1)\n",
    "    y_hat = tf.argmax(Z3, 1)\n",
    "    prediction = sess.run(y_hat, feed_dict = {X: x})\n",
    "    return classes[prediction[0]]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "bed\n",
      "down\n"
     ]
    }
   ],
   "source": [
    "print(inference(\"../data/train/audio/bed/0a7c2a8d_nohash_0.wav\", Z3))\n",
    "print(inference(\"../data/train/audio/down/0a7c2a8d_nohash_0.wav\", Z3))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
