{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Audio Recognition using Tensorflow\n",
    "\n",
    "This approach uses CNN to build a classifier for audio inputs"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Import necessary modules"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import tensorflow as tf\n",
    "from tensorflow.python.framework import ops\n",
    "from utils import *\n",
    "import datetime\n",
    "from time import time\n",
    "from tensorflow.python.client import timeline # for profiling\n",
    "\n",
    "%matplotlib inline\n",
    "np.random.seed(1)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Import the dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train_orig, Y_train_orig, X_test_orig, Y_test_orig, classes = load_data()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Explore the dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "number of training examples = 58248\n",
      "number of test examples = 6473\n",
      "X_train shape: (58248, 16000, 1, 1)\n",
      "Y_train shape: (58248, 30)\n",
      "X_test shape: (6473, 16000, 1, 1)\n",
      "Y_test shape: (6473, 30)\n"
     ]
    }
   ],
   "source": [
    "X_train = X_train_orig\n",
    "X_test = X_test_orig\n",
    "Y_train = convert_to_one_hot(Y_train_orig, classes)\n",
    "Y_test = convert_to_one_hot(Y_test_orig, classes)\n",
    "print (\"number of training examples = \" + str(X_train.shape[0]))\n",
    "print (\"number of test examples = \" + str(X_test.shape[0]))\n",
    "print (\"X_train shape: \" + str(X_train.shape))\n",
    "print (\"Y_train shape: \" + str(Y_train.shape))\n",
    "print (\"X_test shape: \" + str(X_test.shape))\n",
    "print (\"Y_test shape: \" + str(Y_test.shape))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Create input placeholders\n",
    "\n",
    "Tensorflow placeholders for X and Y. These will be dynamically set during batch G.D at runtime"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "def create_placeholders(n_l, n_y):\n",
    "    \"\"\"\n",
    "    Creates the placeholders for the tensorflow session.\n",
    "\n",
    "    Arguments:\n",
    "    n_l -- scalar, length of the audio vector\n",
    "    n_y -- scalar, number of classes\n",
    "\n",
    "    Returns:\n",
    "    X -- placeholder for the data input, of shape [None, n_l] and dtype \"float\"\n",
    "    Y -- placeholder for the input labels, of shape [None, n_y] and dtype \"float\"\n",
    "    \"\"\"\n",
    "    X = tf.placeholder(tf.float32, shape=(None, n_l, 1, 1))\n",
    "    Y = tf.placeholder(tf.float32, shape=(None, n_y))\n",
    "\n",
    "    return X, Y"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "# X, Y = create_placeholders(500, 20)\n",
    "# print (\"X = \" + str(X))\n",
    "# print (\"Y = \" + str(Y))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Initialize Parameters\n",
    "\n",
    "With tensorflow we only need to initialize parameters for Conv layers. Fully connected layers' paramaters are completed handled by the framework."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "def initialize_parameters():\n",
    "    \"\"\"\n",
    "    Initializes weight parameters to build a neural network with tensorflow. The shapes are:\n",
    "    W1 : [4, 1, 1, 8]\n",
    "    W2 : [2, 1, 8, 16]\n",
    "    Returns:\n",
    "    parameters -- a dictionary of tensors containing W1, W2\n",
    "    \"\"\"\n",
    "\n",
    "    tf.set_random_seed(1)\n",
    "\n",
    "    W1 = tf.get_variable(\"W1\", [4,1,1,8], initializer=tf.contrib.layers.xavier_initializer(seed = 0))\n",
    "    W2 = tf.get_variable(\"W2\", [2,1,8,16], initializer=tf.contrib.layers.xavier_initializer(seed = 0))\n",
    "\n",
    "    parameters = {\"W1\": W1, \"W2\": W2}\n",
    "\n",
    "    return parameters"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "# tf.reset_default_graph()\n",
    "# with tf.Session() as sess_test:\n",
    "#     parameters = initialize_parameters()\n",
    "#     init = tf.global_variables_initializer()\n",
    "#     sess_test.run(init)\n",
    "#     print(\"W1 = \" + str(parameters[\"W1\"].eval()[0,0,0]))\n",
    "#     print(\"W2 = \" + str(parameters[\"W2\"].eval()[0,0,0]))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Forward Propagation\n",
    "\n",
    "CONV2D -> RELU -> MAXPOOL -> CONV2D -> RELU -> MAXPOOL -> FLATTEN -> FULLYCONNECTED\n",
    "\n",
    "Following are the parameters for all the layers:\n",
    "    - Conv2D: stride 1, padding is \"SAME\"\n",
    "    - ReLU\n",
    "    - Max pool: 8 by 1 filter size and an 8 by 1 stride, padding is \"SAME\"\n",
    "    - Conv2D: stride 1, padding is \"SAME\"\n",
    "    - ReLU\n",
    "    - Max pool: 4 by 1 filter size and a 4 by 1 stride, padding is \"SAME\"\n",
    "    - Flatten the previous output.\n",
    "    - FULLYCONNECTED (FC) layer: outputs 30 classes one for each audio utterance"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "def forward_propagation(X, parameters):\n",
    "    \"\"\"\n",
    "    Implements the forward propagation for the model:\n",
    "    CONV2D -> RELU -> MAXPOOL -> CONV2D -> RELU -> MAXPOOL -> FLATTEN -> FULLYCONNECTED\n",
    "\n",
    "    Arguments:\n",
    "    X -- input dataset placeholder, of shape (input size, number of examples)\n",
    "    parameters -- python dictionary containing parameters \"W1\", \"W2\"\n",
    "    the shapes are given in initialize_parameters\n",
    "    Returns:\n",
    "    Z3 -- the output of the last LINEAR unit\n",
    "    \"\"\"\n",
    "\n",
    "    # Retrieve the parameters from the dictionary \"parameters\"\n",
    "    W1 = parameters['W1']\n",
    "    W2 = parameters['W2']\n",
    "    regularizer = tf.contrib.layers.l2_regularizer(scale=0.1)\n",
    "#     regularizer = None\n",
    "\n",
    "    Z1 = tf.layers.conv2d(X, 8, (4,1), strides = [1,1], padding = 'SAME', kernel_regularizer = regularizer)\n",
    "    A1 = tf.nn.relu(Z1)\n",
    "    P1 = tf.nn.max_pool(A1, ksize = [1,8,1,1], strides = [1,8,1,1], padding = 'SAME')\n",
    "    Z2 = tf.layers.conv2d(P1, 16, (2, 1), strides = [1,1], padding = 'SAME', kernel_regularizer = regularizer)\n",
    "    A2 = tf.nn.relu(Z2)\n",
    "    P2 = tf.nn.max_pool(A2, ksize = [1,4,1,1], strides = [1,4,1,1], padding = 'SAME')\n",
    "    P2 = tf.contrib.layers.flatten(P2)\n",
    "    Z3 = tf.contrib.layers.fully_connected(P2, 30, activation_fn=None, weights_regularizer = regularizer)\n",
    "\n",
    "    return Z3"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "# tf.reset_default_graph()\n",
    "# with tf.Session() as sess:\n",
    "#     np.random.seed(1)\n",
    "#     X, Y = create_placeholders(64, 5)\n",
    "#     parameters = initialize_parameters()\n",
    "#     Z3 = forward_propagation(X, parameters)\n",
    "#     init = tf.global_variables_initializer()\n",
    "#     sess.run(init)\n",
    "#     a = sess.run(Z3, {X: np.random.randn(2,64,1,1), Y: np.random.randn(2,5)})\n",
    "#     print(\"Z3 = \" + str(a))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Compute Cost\n",
    "\n",
    "Using the last layer Z3, compute softmax and J"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "def compute_cost(Z3, Y):\n",
    "    \"\"\"\n",
    "    Computes the cost\n",
    "\n",
    "    Arguments:\n",
    "    Z3 -- output of forward propagation (output of the last LINEAR unit), of shape (30, number of examples)\n",
    "    Y -- \"true\" labels vector placeholder, same shape as Z3\n",
    "\n",
    "    Returns:\n",
    "    cost - Tensor of the cost function\n",
    "    \"\"\"\n",
    "\n",
    "    cost = tf.reduce_mean(tf.nn.softmax_cross_entropy_with_logits(logits = Z3, labels = Y))\n",
    "\n",
    "    return cost"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "# tf.reset_default_graph()\n",
    "# with tf.Session() as sess:\n",
    "#     np.random.seed(1)\n",
    "#     X, Y = create_placeholders(64, 30)\n",
    "#     parameters = initialize_parameters()\n",
    "#     Z3 = forward_propagation(X, parameters)\n",
    "#     cost = compute_cost(Z3, Y)\n",
    "#     init = tf.global_variables_initializer()\n",
    "#     sess.run(init)\n",
    "#     a = sess.run(cost, {X: np.random.randn(4,64,1,1), Y: np.random.randn(4,30)})\n",
    "#     print(\"cost = \" + str(a))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Model\n",
    "\n",
    "Connects all the functions and sets up training with mini batches"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "tf.reset_default_graph() # to be able to rerun the model without overwriting tf variables\n",
    "\n",
    "config = tf.ConfigProto(device_count = {'GPU': 0})\n",
    "\n",
    "# Start an interactive session\n",
    "sess = tf.InteractiveSession(config=config)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Profiling"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "options = tf.RunOptions(trace_level=tf.RunOptions.FULL_TRACE)\n",
    "run_metadata = tf.RunMetadata()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "def create_model(X_train, Y_train):\n",
    "    \"\"\"\n",
    "    Implements a three-layer ConvNet in Tensorflow:\n",
    "    CONV2D -> RELU -> MAXPOOL -> CONV2D -> RELU -> MAXPOOL -> FLATTEN -> FULLYCONNECTED\n",
    "\n",
    "    Arguments:\n",
    "    X_train -- training set, of shape (None, 16000, 1, 1)\n",
    "    Y_train -- test set, of shape (None, n_y = 30)\n",
    "    X_test -- training set, of shape (None, 16000, 1, 1)\n",
    "    Y_test -- test set, of shape (None, n_y = 30)\n",
    "    learning_rate -- learning rate of the optimization\n",
    "    num_epochs -- number of epochs of the optimization loop\n",
    "    minibatch_size -- size of a minibatch\n",
    "    print_cost -- True to print the cost every 100 epochs\n",
    "\n",
    "    Returns:\n",
    "    train_accuracy -- real number, accuracy on the train set (X_train)\n",
    "    test_accuracy -- real number, testing accuracy on the test set (X_test)\n",
    "    parameters -- parameters learnt by the model. They can then be used to predict.\n",
    "    \"\"\"\n",
    "\n",
    "    tf.set_random_seed(1) # to keep results consistent (tensorflow seed)\n",
    "    (m, n_l, _, __) = X_train.shape\n",
    "    n_y = Y_train.shape[1]\n",
    "\n",
    "    X, Y = create_placeholders(n_l, n_y)\n",
    "    parameters = initialize_parameters()\n",
    "    Z3 = forward_propagation(X, parameters)\n",
    "    cost = compute_cost(Z3, Y)\n",
    "    # print(\"Cost before iteration %s\" % (cost,))\n",
    "\n",
    "    return Z3, X, Y, parameters, cost"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "def run_model(X_train, Y_train, cost,learning_rate = 0.009, minibatch_size = 64, num_epochs = 100, init_vars = False, print_cost = True):\n",
    "    \n",
    "    seed = 3 # to keep results consistent (numpy seed)\n",
    "    m = X_train.shape[0]\n",
    "    num_minibatches = int(m / minibatch_size) # number of minibatches of size minibatch_size in the train set\n",
    "    costs = [] # To keep track of the cost\n",
    "    \n",
    "    # Backpropagation: Using AdamOptimizer to minimize the cost.\n",
    "    optimizer = tf.train.AdamOptimizer(learning_rate = learning_rate).minimize(cost)\n",
    "    \n",
    "    if init_vars:\n",
    "        # Run the initialization\n",
    "        sess.run(tf.global_variables_initializer())\n",
    "    \n",
    "    # Do the training loop\n",
    "    for epoch in range(num_epochs):\n",
    "        minibatch_cost = 0.\n",
    "        # print(\"> epoch = %s, m = %s, mini size = %s, mini cost = %s\" % (epoch, m, minibatch_size, minibatch_cost))\n",
    "        seed = seed + 1\n",
    "        minibatches = random_mini_batches(X_train, Y_train, minibatch_size, seed)\n",
    "        for minibatch in minibatches:\n",
    "            (minibatch_X, minibatch_Y) = minibatch\n",
    "            # print(\">> mini X.shape = %s, mini Y.shape = %s\" % (minibatch_X.shape, minibatch_Y.shape))\n",
    "            # IMPORTANT: The line that runs the graph on a minibatch.\n",
    "            # Run the session to execute the optimizer and the cost, the feedict should contain a minibatch for (X,Y).\n",
    "            _ , temp_cost = sess.run([optimizer, cost], feed_dict = {X: minibatch_X, Y: minibatch_Y})\n",
    "            # print(\">> Temp cost = %s\" % temp_cost)\n",
    "            minibatch_cost += temp_cost / num_minibatches\n",
    "\n",
    "        # Print the cost every epoch\n",
    "        if print_cost == True and epoch % 5 == 0:\n",
    "            print(\"%s: Cost after epoch %i: %f\" % (datetime.datetime.now().strftime('%Y-%m-%d %H:%M:%S'), epoch, minibatch_cost))\n",
    "        if print_cost == True and epoch % 1 == 0:\n",
    "            costs.append(minibatch_cost)\n",
    "\n",
    "\n",
    "    # plot the cost\n",
    "    plt.plot(np.squeeze(costs))\n",
    "    plt.ylabel('cost')\n",
    "    plt.xlabel('iterations (per tens)')\n",
    "    plt.title(\"Learning rate =\" + str(learning_rate))\n",
    "    plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "Z3, X, Y, parameters, cost = create_model(X_train, Y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2018-01-05 10:03:08: Cost after epoch 0: 2.991563\n",
      "2018-01-05 10:10:53: Cost after epoch 5: 1.914550\n",
      "2018-01-05 10:18:30: Cost after epoch 10: 1.546726\n",
      "2018-01-05 10:26:10: Cost after epoch 15: 1.335233\n",
      "2018-01-05 10:33:46: Cost after epoch 20: 1.231143\n",
      "2018-01-05 10:41:25: Cost after epoch 25: 1.164946\n",
      "2018-01-05 10:49:01: Cost after epoch 30: 1.099884\n",
      "2018-01-05 10:56:37: Cost after epoch 35: 1.045431\n",
      "2018-01-05 11:03:59: Cost after epoch 40: 1.040445\n",
      "2018-01-05 11:11:27: Cost after epoch 45: 0.982155\n",
      "2018-01-05 11:18:49: Cost after epoch 50: 0.970236\n",
      "2018-01-05 11:26:16: Cost after epoch 55: 0.926154\n",
      "2018-01-05 11:33:38: Cost after epoch 60: 0.896410\n",
      "2018-01-05 11:40:57: Cost after epoch 65: 0.912037\n",
      "2018-01-05 11:48:15: Cost after epoch 70: 0.887926\n",
      "2018-01-05 11:55:43: Cost after epoch 75: 0.863580\n",
      "2018-01-05 12:03:08: Cost after epoch 80: 0.850788\n",
      "2018-01-05 12:10:33: Cost after epoch 85: 0.823060\n",
      "2018-01-05 12:17:57: Cost after epoch 90: 0.826029\n",
      "2018-01-05 12:25:22: Cost after epoch 95: 0.798216\n",
      "2018-01-05 12:32:47: Cost after epoch 100: 0.797406\n",
      "2018-01-05 12:40:14: Cost after epoch 105: 0.824500\n",
      "2018-01-05 12:47:40: Cost after epoch 110: 0.756124\n",
      "2018-01-05 12:55:06: Cost after epoch 115: 0.758903\n",
      "2018-01-05 13:02:32: Cost after epoch 120: 0.750762\n"
     ]
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<matplotlib.figure.Figure at 0x91a7b50>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "run_model(X_train, Y_train, cost, learning_rate = 0.011, minibatch_size = 256, num_epochs = 125, init_vars = True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Save profilind data to disk"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create the Timeline object, and write it to a json file\n",
    "fetched_timeline = timeline.Timeline(run_metadata.step_stats)\n",
    "chrome_trace = fetched_timeline.generate_chrome_trace_format()\n",
    "time_id = int(time())\n",
    "with open('../experiments/timeline_256b_120e_gpu0_l2_%s.json' % (time_id,), 'w') as f:\n",
    "    f.write(chrome_trace)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Save model to disk"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# saver = tf.train.Saver()\n",
    "# saver.save(sess, '../saved_models/cnn-tf-model')\n",
    "\n",
    "meta_graph_def = tf.train.export_meta_graph(filename='../saved_models/my-cnn-tf-model.meta')\n",
    "meta_graph_def"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(\"W1 = \" + str(parameters[\"W1\"].eval()[0,0,0]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(tf.train.latest_checkpoint('../saved_models/'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "def model_accuracy(X_train, Y_train, Z3, X, Y, minibatch_size = 64, print_progress = True):\n",
    "    predict_op = tf.argmax(Z3, 1)\n",
    "    correct_prediction = tf.equal(predict_op, tf.argmax(Y, 1))\n",
    "    accuracy = tf.reduce_mean(tf.cast(correct_prediction, \"float\"))\n",
    "    \n",
    "    num_minibatches = 0\n",
    "    acc_accuracy = 0\n",
    "    minibatches = random_mini_batches(X_train, Y_train, minibatch_size)\n",
    "    for minibatch in minibatches:\n",
    "        (minibatch_X, minibatch_Y) = minibatch\n",
    "        acc_accuracy += accuracy.eval({X: minibatch_X, Y: minibatch_Y})\n",
    "        num_minibatches += 1\n",
    "        \n",
    "        if num_minibatches % 25 == 0:\n",
    "            print(\"%s: Accuracy after %ith batch: %f\" % (datetime.datetime.now().strftime('%Y-%m-%d %H:%M:%S'), num_minibatches, acc_accuracy / num_minibatches))\n",
    "\n",
    "    train_accuracy = acc_accuracy / num_minibatches\n",
    "    print(\"Accuracy:\", train_accuracy)\n",
    "\n",
    "    return train_accuracy"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "sess.list_devices()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2018-01-05 13:13:25: Accuracy after 25th batch: 0.764844\n",
      "2018-01-05 13:13:28: Accuracy after 50th batch: 0.764297\n",
      "2018-01-05 13:13:30: Accuracy after 75th batch: 0.762760\n",
      "2018-01-05 13:13:32: Accuracy after 100th batch: 0.761680\n",
      "2018-01-05 13:13:34: Accuracy after 125th batch: 0.762156\n",
      "2018-01-05 13:13:37: Accuracy after 150th batch: 0.762109\n",
      "2018-01-05 13:13:39: Accuracy after 175th batch: 0.762567\n",
      "2018-01-05 13:13:41: Accuracy after 200th batch: 0.762656\n",
      "2018-01-05 13:13:44: Accuracy after 225th batch: 0.761493\n",
      "('Accuracy:', 0.76145974429030172)\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "0.76145974429030172"
      ]
     },
     "execution_count": 22,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# train_accuracy, test_accuracy = model_accuracy(X_train, Y_train, X_test, Y_test, Z3, X, Y)\n",
    "# test_accuracy = model_accuracy(X_train, Y_train, X_test, Y_test, Z3, X, Y)\n",
    "model_accuracy(X_train, Y_train, Z3, X, Y, minibatch_size = 256)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2018-01-05 13:14:43: Accuracy after 25th batch: 0.221406\n",
      "('Accuracy:', 0.21973994030402258)\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "0.21973994030402258"
      ]
     },
     "execution_count": 23,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model_accuracy(X_test, Y_test, Z3, X, Y, minibatch_size = 256)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Inference\n",
    "\n",
    "- Convert audio file to vector and reshape\n",
    "- Do forward prop\n",
    "- Find the maximal class\n",
    "- Remap index to class name"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def inference(audio_file, Z3):\n",
    "    ra = load_wav_file(os.path.abspath(audio_file))\n",
    "    x = ra.reshape(1, ra.shape[0], 1, 1)\n",
    "    y_hat = tf.argmax(Z3, 1)\n",
    "    prediction = sess.run(y_hat, feed_dict = {X: x})\n",
    "    return classes[prediction[0]]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(inference(\"../data/train/audio/bed/0a7c2a8d_nohash_0.wav\", Z3)) # bed\n",
    "print(inference(\"../data/train/audio/down/0a7c2a8d_nohash_0.wav\", Z3)) # down\n",
    "print(inference(\"../data/test/audio/clip_0000adecb.wav\", Z3)) # happy"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "classes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
